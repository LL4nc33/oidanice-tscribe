# WHY docker-compose: Single command to launch all 4 services with correct
# networking, dependency ordering, and shared volumes. Developers run
# `docker compose up` instead of managing 4 separate containers.

services:
  # WHY redis first: Both api (job enqueue) and worker (job dequeue) depend
  # on Redis as the job queue backend via RQ (Redis Queue).
  redis:
    image: redis:7-alpine
    # WHY alpine variant: ~30MB vs ~130MB for full image. Redis needs no
    # extra OS packages, so alpine is ideal.
    # WHY requirepass: Prevents unauthorized cross-container access to Redis.
    # Simple password is fine for self-hosted private network deployment.
    command: redis-server --requirepass ${REDIS_PASSWORD:-tscribe-redis-secret}
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD:-tscribe-redis-secret}
    # WHY healthcheck: Ensures dependent services only start when Redis
    # is actually accepting connections, not just when the container starts.
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "tscribe-redis-secret", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    depends_on:
      redis:
        condition: service_healthy
    env_file:
      - .env
    environment:
      - TSCRIBE_REDIS_URL=redis://:${REDIS_PASSWORD:-tscribe-redis-secret}@redis:6379/0
    # WHY shared data volume: SQLite database and downloaded audio files
    # must be accessible by both api (creates jobs, serves results) and
    # worker (downloads audio, writes transcriptions).
    volumes:
      - ./data:/data
    # WHY healthcheck: Detects when the FastAPI server is stuck or
    # unresponsive. Uses Python urllib because curl is not installed
    # in python:3.12-slim.
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/api/health')"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped

  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    # WHY override CMD: Same image as api but runs the RQ worker process
    # instead of the FastAPI server. Shares code, deps, and config.
    command: python run_worker.py
    depends_on:
      redis:
        condition: service_healthy
      api:
        # WHY depends on api: Ensures database is initialized (api creates
        # tables on startup) before worker tries to update job records.
        condition: service_healthy
    env_file:
      - .env
    environment:
      - TSCRIBE_REDIS_URL=redis://:${REDIS_PASSWORD:-tscribe-redis-secret}@redis:6379/0
    volumes:
      - ./data:/data
    # WHY healthcheck: Verifies the RQ worker process is alive and Redis
    # is reachable. Uses Python to check Redis connectivity since the
    # worker has no HTTP endpoint to probe.
    healthcheck:
      test: ["CMD", "python", "-c", "from redis import Redis; from app.config import settings; Redis.from_url(settings.redis_url).ping()"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s
    # WHY: Transcription of one segment can take up to ~30s on CPU. After
    # SIGTERM sets the shutdown flag, the worker needs to finish the current
    # segment, mark the job as FAILED in SQLite, and exit. 60s is generous
    # enough for slow hardware but not so long that deploys feel stuck.
    # (Docker default is 10s, which is too short for transcription cleanup.)
    stop_grace_period: 60s
    # WHY: GPU config commented out - uncomment if NVIDIA GPU available.
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        APP_VERSION: ${APP_VERSION:-0.0.4a}
    ports:
      - "58008:8080"
    depends_on:
      api:
        condition: service_healthy
    # WHY healthcheck: Detects when nginx is unresponsive. Uses wget
    # because it is available in nginx:alpine by default (curl is not).
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://127.0.0.1:8080/"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 5s
    restart: unless-stopped
